{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "raw_data = {}\n",
    "keys = ['rr', 'll', 'r']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_file_name_pattern = 'worker_(.*).log'\n",
    "\n",
    "for key in keys:\n",
    "    files = os.listdir('./logs/%s/' % key)\n",
    "    num_workers = len(files) - 1\n",
    "    \n",
    "    master_data = None\n",
    "    worker_data = {}\n",
    "    for file in files:\n",
    "        \n",
    "        file_pointer = open('./logs/%s/%s' % (key, file), 'r')\n",
    "        file_data = file_pointer.readlines()\n",
    "        \n",
    "        if file == 'yacs.log':\n",
    "            master_data = file_data\n",
    "            continue\n",
    "            \n",
    "        worker_id = re.match('worker_(.*).log', file, re.DOTALL).group(1)\n",
    "        if not worker_id:\n",
    "            continue\n",
    "        \n",
    "        worker_data[worker_id] = file_data\n",
    "        \n",
    "    raw_data[key] = {}\n",
    "    raw_data[key]['master_data'] = master_data\n",
    "    raw_data[key]['worker_data'] = worker_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "worker_task_received_pattern = 'INFO (\\d+/\\d+/\\d+) (\\d+:\\d+:\\d+\\.\\d+): task recieved: (.*) of job: (.*)'\n",
    "worker_task_completed_pattern = 'INFO (\\d+/\\d+/\\d+) (\\d+:\\d+:\\d+\\.\\d+): task completed: (.*) of job: (.*)'\n",
    "\n",
    "job_received_pattern = 'INFO (\\d+/\\d+/\\d+) (\\d+:\\d+:\\d+\\.\\d+): scheduling job: (.+) recieved from .*'\n",
    "job_completed_pattern = 'INFO (\\d+/\\d+/\\d+) (\\d+:\\d+:\\d+\\.\\d+): job (.+) completed'\n",
    "\n",
    "master_task_scheduled_pattern = 'INFO (\\d+/\\d+/\\d+) (\\d+:\\d+:\\d+\\.\\d+): task (.*) from (.*) scheduled on (.*)'\n",
    "master_task_completed_pattern = 'INFO (\\d+/\\d+/\\d+) (\\d+:\\d+:\\d+\\.\\d+): completed task (.*)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "for key in keys:\n",
    "    master_data = raw_data[key]['master_data']\n",
    "    worker_data = raw_data[key]['worker_data']\n",
    "    \n",
    "    # Find Master Data\n",
    "    jobs_buffer = {}\n",
    "    jobs = []\n",
    "    \n",
    "    worker_ids = list(worker_data.keys())\n",
    "    initial_timestamp = {}\n",
    "    for worker_id in worker_ids:\n",
    "        initial_timestamp[worker_id] = 0\n",
    "        \n",
    "    tasks = []\n",
    "    tasks_buffer = {}\n",
    "    tasks.append(initial_timestamp)\n",
    "    \n",
    "    for line in master_data:\n",
    "        match_obj = re.match(job_received_pattern, line.strip(), re.DOTALL)\n",
    "        if match_obj:\n",
    "            date = match_obj.group(1)\n",
    "            time = match_obj.group(2)\n",
    "            job_id = match_obj.group(3)\n",
    "            \n",
    "            jobs_buffer[job_id] = date + ' ' + time\n",
    "            continue\n",
    "            \n",
    "        match_obj = re.match(job_completed_pattern, line.strip(), re.DOTALL)\n",
    "        if match_obj:\n",
    "            date = match_obj.group(1)\n",
    "            time = match_obj.group(2)\n",
    "            job_id = match_obj.group(3)\n",
    "            if job_id not in jobs_buffer:\n",
    "                continue\n",
    "            receive_time = jobs_buffer[job_id]\n",
    "            \n",
    "            jobs.append({\n",
    "                'job_id': job_id,\n",
    "                'arrival_time': receive_time,\n",
    "                'end_time': date + ' ' + time\n",
    "            })\n",
    "            continue\n",
    "            \n",
    "        match_obj = re.match(master_task_scheduled_pattern, line.strip(), re.DOTALL)\n",
    "        if match_obj:\n",
    "            date = match_obj.group(1)\n",
    "            time = match_obj.group(2)\n",
    "            task_id = match_obj.group(3)\n",
    "            worker_id = match_obj.group(5)\n",
    "            \n",
    "            curr_timestamp = deepcopy(tasks[-1])\n",
    "            curr_timestamp[worker_id] += 1\n",
    "            curr_timestamp['timestamp'] = date + ' ' + time\n",
    "            tasks_buffer[task_id] = worker_id\n",
    "            tasks.append(curr_timestamp)\n",
    "            \n",
    "        match_obj = re.match(master_task_completed_pattern, line.strip(), re.DOTALL)\n",
    "        if match_obj:\n",
    "            date = match_obj.group(1)\n",
    "            time = match_obj.group(2)\n",
    "            task_id = match_obj.group(3)\n",
    "            \n",
    "            worker_id = tasks_buffer[task_id]\n",
    "            \n",
    "            curr_timestamp = deepcopy(tasks[-1])\n",
    "            curr_timestamp[worker_id] -= 1\n",
    "            curr_timestamp['timestamp'] = date + ' ' + time\n",
    "            tasks.append(curr_timestamp)\n",
    "    master_data = {\n",
    "        'jobs': jobs,\n",
    "        'tasks': tasks\n",
    "    }\n",
    "    \n",
    "    #Find Worker Data\n",
    "    \n",
    "    tasks_buffer = {}\n",
    "    worker_info = {}\n",
    "    \n",
    "    for worker_id in worker_data:\n",
    "        \n",
    "        worker_tasks = []\n",
    "        \n",
    "        for line in worker_data[worker_id]:\n",
    "            match_obj = re.match(worker_task_received_pattern, line.strip(), re.DOTALL)\n",
    "            if match_obj:\n",
    "                date = match_obj.group(1)\n",
    "                time = match_obj.group(2)\n",
    "                task_id = match_obj.group(3)\n",
    "\n",
    "                tasks_buffer[task_id] = date + ' ' + time\n",
    "                continue\n",
    "\n",
    "            match_obj = re.match(worker_task_completed_pattern, line.strip(), re.DOTALL)\n",
    "            if match_obj:\n",
    "                date = match_obj.group(1)\n",
    "                time = match_obj.group(2)\n",
    "                task_id = match_obj.group(3)\n",
    "                if task_id not in tasks_buffer:\n",
    "                    continue\n",
    "                receive_time = tasks_buffer[task_id]\n",
    "\n",
    "                worker_tasks.append({\n",
    "                    'task_id': task_id,\n",
    "                    'arrival_time': receive_time,\n",
    "                    'end_time': date + ' ' + time\n",
    "                })\n",
    "                continue\n",
    "\n",
    "        worker_info[worker_id] = worker_tasks\n",
    "        \n",
    "    data[key] = {\n",
    "        'master_data': master_data,\n",
    "        'worker_data': worker_info\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'w') as fp:\n",
    "    json.dump(data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
